---
title: "Support Vector Machine"
author: "Jason"
date: "2015年8月30日"
output: 
  html_document: 
    fig_width: 6
    keep_md: yes
  Mainfont: Calibri
  fontsize: 12pts
---
```{r setup, echo=FALSE}
knitr::opts_chunk$set(comment="")
knitr::opts_chunk$set(fig.align='center')
```

```{r package}
library(ISLR); library(e1071)
library(ggplot2); library(dplyr); library(reshape2)
```
# Not linearly seperate
```{r data_setting}
set.seed(1)
x <- matrix(rnorm(20*2), ncol=2)
y <- rep(c(1, -1), each=10)
x[y == 1, ] <- x[y == 1, ] + 1
```

```{r plot1}
data <- data.frame(x=x, y=as.factor(y))
g1 <- ggplot(data) + geom_point(aes(x=x.1, y=x.2, color=y), shape=16, size=4) + ggtitle("Scatter Plot") + xlab("X1") + ylab("X2") + scale_color_manual(values=c("dodgerblue", "darkorange"))
g1
```

```{r svm}
svm.fit <- svm(y ~ ., data=data, kernel="linear", cost=10, scale=FALSE)
```

```{r coefficient}
#Get the coefficient
coefs <- t(svm.fit$coefs) %*% svm.fit$SV
b <- -coefs[1]/coefs[2]
#Intercept
a <- svm.fit$rho
```

```{r ggplot_visual}
g1 + geom_abline(intercept=a, slope=b)
x_max <- apply(x, 2, max)
x_min <- apply(x, 2, min)
x1var <- seq(x_max[1], x_min[1], length.out=100)
x2var <- seq(x_max[2], x_min[2], length.out=100)
mydata <- expand.grid(x1var, x2var)
mydata$z <- as.factor(((mydata[, 1]*coefs[1] + mydata[, 2]*coefs[2] + b) > 0)*1)
ggplot(mydata) + geom_tile(aes(x=Var1, y=Var2, z=z, fill=z), alpha=0.8) + theme_bw() + scale_fill_manual(values=c("dodgerblue", "darkorange"))
```

```{r}
mydata <- expand.grid(x1var, x2var)
mydata2 <- as.data.frame(rbind(as.matrix(mydata), x))

mydata2$z <- as.factor(c(((mydata[, 1]*coefs[1] + mydata[, 2]*coefs[2] + b) > 0)*2 - 1, y))
mydata2$o <- rep(c(0, 1), c(10000, 20))
ggplot(mydata2) + geom_point(aes(x=Var1, y=Var2, color=z, size=o), shape=19) + theme_bw() + scale_color_manual(values=c("dodgerblue", "darkorange"))
```

```{r basic_visual}
plot(svm.fit, data)
```

```{r support_Vector}
#We can use index to find out those observation in support vector machine
svm.fit$index
```

```{r cross_validation}
#Cross-validation by tune
svm.cv <- tune(svm, y ~ ., data=data, kernel="linear", range=list(cost=c(0.001, 0.01, 0.1, 1, 10, 100, 1000)))
summary(svm.cv)
```

```{r best}
final.model <- svm.cv$best.model
summary(final.model)
```

```{r basic_visual_final}
plot(final.model, data)
```

```{r test}
x.test <- matrix(rnorm(20*2), ncol=2)
y.test <- rep(c(1, -1), each=10)
x.test[y.test == 1, ] <- x.test[y.test == 1, ] + 1
testdata <- data.frame(x=x.test, y=as.factor(y.test))
#Prediction
y.predict <- predict(final.model, testdata)
table(Predict=y.predict, True=y.test)
```

# Linearly seperate
```{r data_setting2}
set.seed(1)
xl <- matrix(rnorm(20*2), ncol=2)
y <- rep(c(-1, 1), each=10)
xl[y == 1] <- x[y == 1] + 3
```


```{r plot2}
data2 <- data.frame(x=xl, y=as.factor(y))
ggplot(data2) + geom_point(aes(x=x.1, y=x.2, color=y), shape=16, size=4) + ggtitle("Scatter Plot") + xlab("X1") + ylab("X2") + scale_color_manual(values=c("dodgerblue", "darkorange"))
```

```{r svm.fit2}
svm.fit2 <- svm(y ~ ., data=data2, kernel="linear", cost=1e5)
summary(svm.fit2)
```

```{r}
plot(svm.fit2, data)
```

